defaults:
  - override hydra/launcher: submitit_slurm

sweep:
  n_sample: 100
  n_seed_per_sample: 1

seed: 0
n_resumes: 5

# dataset should be one of {mushroom,nursery,connect4,uscensus90,pokerhand,forests}
dataset: mushroom
flow_type: coupling  # {coupling,autoreg}
num_flows: 16
num_dequant_flows: 4
hdims: [256, 256]
actfn: relu
dequantization: voronoi
use_dequant_flow: True
cond_embed_dim: 8
arch: mlp
num_transformer_layers: 2
transformer_d_model: 256
transformer_dropout: 0.0

block_transform: affine
num_mixtures: 8

use_contextnet: True

skip_eval: False

embedding_dim: 3
share_embeddings: False
use_logit_transform: False
learn_box_constraints: True

# base should be one of {gaussian, resampled}
base: resampled
resampled:
  actfn: relu
  hdims: [256, 256]

iterations: 200000
batch_size: 64
lr: 0.0005
weight_decay: 0
warmup: 0

ema_eval: True
eval_batch_size: 32
num_eval_samples: 100

logfreq: 100
evalfreq: 1000

hydra:
  run:
    dir: ./exp_local/uci_categorical/${dataset}/${dequantization}/${now:%Y.%m.%d}/${now:%H%M%S}
  sweep:
    dir: ./exp/uci_categorical/${dataset}/${dequantization}/${now:%Y.%m.%d}/${now:%H%M%S}
    subdir: ${hydra.job.num}
  launcher:
    max_num_timeout: 100000
    timeout_min: 4319
    partition: learnfair
    mem_gb: 64
    cpus_per_task: 10
    gpus_per_node: 1
